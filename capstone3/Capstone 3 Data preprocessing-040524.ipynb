{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c06bbb7",
   "metadata": {},
   "source": [
    "# 3 Data Preprocessing<a id='3_Data_Preprocessing'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b90e8f11",
   "metadata": {},
   "source": [
    "## 3.1 Contents<a id='2.1_Contents'></a>\n",
    "* [2 Data wrangling](#2_Data_wrangling)\n",
    "  * [2.1 Contents](#2.1_Contents)\n",
    "  * [2.2 Introduction](#2.2_Introduction)\n",
    "    * [2.2.1 Recap Of Data Science Problem](#2.2.1_Recap_Of_Data_Science_Problem)\n",
    "    * [2.2.2 Objective of Data Wrangling](#2.2.2_Objective_of_Data_Wrangling)\n",
    "  * [2.3 Imports](#2.3_Imports)\n",
    "  * [2.4 Load The Data](#2.4_Load_The_Data)\n",
    "  * [2.5 Explore The Data](#2.5_Explore_The_Data)\n",
    "    * [2.5.1 Find Duplicates](#2.5.1_Find_Duplicates)\n",
    "    * [2.5.2 Find Missing Values](#2.5.2_Find_Missing_Values)\n",
    "    * [2.5.3 Find Dimensions for Time Series](#2.5.3_Find_Dimensions_for_Time_Series)\n",
    "      * [2.5.3.1 Total Number of Time Series](#2.5.3.1_Total_Number_of_Time_Series)\n",
    "      * [2.5.3.2 Time Span of Time Series](#2.5.3.2_Time_Span_of_Time_Series)\n",
    "        * [2.5.3.2.1 Time Span of Time Series in Weekly_sales Dataframe](#2.5.3.2.1_Time_Span_of_Time_Series_in_Weekly_sales_Dataframe)\n",
    "        * [2.5.3.2.2 Time Span of Time Series in Features Dataframe](#2.5.3.2.2_Time_Span_of_Time_Series_in_Features _Dataframe)\n",
    "    * [2.5.4 Time Trend of Weekly Sales](#2.5.4_Time_Trend_of_Weekly_Sales)\n",
    "      * [2.5.4.1 Time Trend of Weekly Sales for Dept](#2.5.4.1_Time_Trend_of_Weekly_Sales_for_Dept)\n",
    "      * [2.5.4.2 Completeness of Weekly Sales Records](#2.5.4.2_Completeness_of_Weekly_Sales_Records)\n",
    "    * [2.5.5 Categorical Features](#2.5.5_Categorical_Features)\n",
    "      * [2.5.5.1 Store Type](#2.5.5.1_Store_Type)\n",
    "        * [2.5.5.1.1 Store Size for Different Store Type](#2.5.5.1.1_Store_Size_for_Different_Store_Type)\n",
    "        * [2.5.5.1.2 Weekly Sales for Different Store Type](#2.5.5.1.2_Weekly_Sales_for_Different_Store_Type)\n",
    "      * [2.5.5.2 Holiday Effect](#2.5.5.2_Holiday_Effect)\n",
    "    * [2.5.6 Numerical Features](#2.5.6_Numerical_Features)\n",
    "      * [2.5.6.1 Numerical Variables in features df](#2.5.6.1_Numerical_Variables_in_Features_df)\n",
    "        * [2.5.6.1.1 Numerical Variables Summary](#2.5.6.1.1_Numerical_Variables_Summary)\n",
    "        * [2.5.6.1.2 Numerical Variables Distribution](#2.5.6.1.2_Numerical_Variables_Distribution)\n",
    "      * [2.5.6.2 Numerical Variables in weekly_sales_type df](#2.5.6.2_Numerical_Variables_in_Weekly_Sales_Type_df)\n",
    "  * [2.6 Merge The Data](#2.6_Merge_The_Data)\n",
    "  * [2.7 Save The dData](#2.7_Save_The_data)\n",
    "  * [2.8 Summary](#2.8_Summary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c0d44a",
   "metadata": {},
   "source": [
    "## 3.2 Objectives<a id='3.2_Objectives'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a6e2815",
   "metadata": {},
   "source": [
    "2. Image preprocessing \n",
    "    \n",
    "    1) Image normalization due to various image intensity \n",
    "    \n",
    "    2) noise reduction technique - guassian blurring\n",
    "    \n",
    "    3) image augmentation\n",
    "    \n",
    "    4) ROI selection?\n",
    "    \n",
    "\n",
    "3. feature extraction\n",
    "    1) statistical features like intensity mean, standard deviation, skewness, and kurtosis from the pixel intensity distributions.\n",
    " \n",
    "    2) Shape and Contour Features: Hough Transform for detecting shapes in the X-ray which might be indicative of particular conditions.\n",
    "    \n",
    "    3) texture/orientation features: Gabor Filters\n",
    "    \n",
    "    4) deep learning CNNs\n",
    "  \n",
    "4. sample imbalance\n",
    "   1) number in different cases are largely different, data imbalance might be a concern\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98237765",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install keras-tuner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b39d579d",
   "metadata": {},
   "source": [
    "## 3.3 Imports<a id='3.3_Imports'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73565c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libs  \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation,Dense, Flatten,BatchNormalization, Conv2D,MaxPool2D,Dropout, Rescaling\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import categorical_crossentropy\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import keras_tuner\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import glob\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229b232c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b8099c11",
   "metadata": {},
   "source": [
    "## 3.4 Test_Train_split<a id='3.4_Test_Train_split'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f01f3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['COVID', 'Normal', 'Viral Pneumonia', 'Lung_Opacity']  # List of categories\n",
    "\n",
    "'''\n",
    "def select_files(folder,proportion):\n",
    "    files=[f for f in os.listdir(folder) if f.lower().endswith('.png','.jpg','jpeg')]\n",
    "    num_selected_files=int(len(files)*proportion)\n",
    "    selected_files=np.random.cjoice()files,num_selected_files,replace=False)\n",
    "    return selected_files\n",
    "'''\n",
    "\n",
    "# Set a random seed for reproducibility\n",
    "seed = 42\n",
    "\n",
    "# Define a split ratio\n",
    "train_ratio = 0.7\n",
    "validation_ratio = 0.1\n",
    "test_ratio = 0.2 \n",
    "\n",
    "# Define the base directories for train and test sets\n",
    "base_train_dir = 'train'\n",
    "base_validation_dir = 'validation'\n",
    "base_test_dir = 'test'\n",
    "\n",
    "# Create train and test directories if they don't exist\n",
    "if not os.path.exists(base_train_dir):\n",
    "    os.makedirs(base_train_dir)\n",
    "    \n",
    "if not os.path.exists(base_validation_dir):\n",
    "    os.makedirs(base_validation_dir)\n",
    "\n",
    "if not os.path.exists(base_test_dir):\n",
    "    os.makedirs(base_test_dir)\n",
    "\n",
    "for category in categories:\n",
    "    # Create category subdirectories in train and test directories\n",
    "    train_category_dir = os.path.join(base_train_dir, category)\n",
    "    validation_category_dir = os.path.join(base_validation_dir, category)\n",
    "    test_category_dir = os.path.join(base_test_dir, category)\n",
    "\n",
    "    if not os.path.exists(train_category_dir):\n",
    "        os.makedirs(train_category_dir)\n",
    "        \n",
    "    if not os.path.exists(validation_category_dir):\n",
    "        os.makedirs(validation_category_dir)\n",
    "    \n",
    "    if not os.path.exists(test_category_dir):\n",
    "        os.makedirs(test_category_dir)\n",
    "\n",
    "    # Get the list of images from the first subdirectory of the category\n",
    "    subfolders = [d for d in os.listdir(category) if os.path.isdir(os.path.join(category, d))]  \n",
    "    first_subfolder = os.path.join(category, subfolders[0])\n",
    "    if os.path.isdir(first_subfolder):\n",
    "        images = [img for img in os.listdir(first_subfolder) if img.endswith('.png')]\n",
    "\n",
    "    # Train-test split for the current category\n",
    "     # Select only 10% of images to use for this category\n",
    "    _, use_images = train_test_split(images, test_size=0.3, random_state=seed)\n",
    "    train_val_images, test_images = train_test_split(use_images, test_size=test_ratio, random_state=seed)\n",
    "    train_images, val_images = train_test_split(train_val_images, test_size=validation_ratio/(train_ratio+validation_ratio), random_state=seed)\n",
    "\n",
    "    # Move images to their respective train/test category directories\n",
    "    for img in train_images:\n",
    "        source = os.path.join(category, subfolders[0], img)\n",
    "        destination = os.path.join(train_category_dir, img)\n",
    "        shutil.move(source, destination)\n",
    "        \n",
    "    for img in val_images:\n",
    "        source = os.path.join(category, subfolders[0], img)\n",
    "        destination = os.path.join(validation_category_dir, img)\n",
    "        shutil.move(source, destination)\n",
    "\n",
    "    for img in test_images:\n",
    "        source = os.path.join(category, subfolders[0], img)\n",
    "        destination = os.path.join(test_category_dir, img)\n",
    "        shutil.move(source, destination)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b95c55e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ee380e5a",
   "metadata": {},
   "source": [
    "## 3.5 Baseline Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20cb318b",
   "metadata": {},
   "source": [
    "### 3.5.1 Image preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0241183",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 551 images belonging to 4 classes.\n",
      "Found 82 images belonging to 4 classes.\n",
      "Found 159 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "#generate batches of data which can be put in sequential model \n",
    "\n",
    "#you can add augmentation or rescaling parameters here\n",
    "#Frist, start without setting any parameters, since basic model already add rescaling function\n",
    "Image_generator=ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "#creat batches of data from directory where train,val,test dataset are, target_size are set as 224 since pre-trained model VGG16 is using image with size of 224\n",
    "train_batches=Image_generator.flow_from_directory(directory=base_train_dir,target_size=(299,299), classes=['COVID', 'Normal', 'Viral Pneumonia', 'Lung_Opacity'],batch_size=10)\n",
    "val_batches=Image_generator.flow_from_directory(directory=base_validation_dir,target_size=(299,299), classes=['COVID', 'Normal', 'Viral Pneumonia', 'Lung_Opacity'],batch_size=10)\n",
    "#only set shuffle to be false for test dataset since we need to use test dataset as reference for confusion matrix where\n",
    "test_batches=Image_generator.flow_from_directory(directory=base_test_dir,target_size=(299,299), classes=['COVID', 'Normal', 'Viral Pneumonia', 'Lung_Opacity'],batch_size=10,shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f55033",
   "metadata": {},
   "outputs": [],
   "source": [
    "#each batch contains 10 images and corresponding labels\n",
    "imgs,labels=next(train_batches)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f16ccaf7",
   "metadata": {},
   "source": [
    "def adjustImages(image):\n",
    "    min_val=np.min(img)\n",
    "    max_val=np.max(img)\n",
    "    adjusted_img=(img-min_val)/(max_val-min_val)\n",
    "    return adjusted_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d20796",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_images=imgs.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f2450e",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e67578",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axes=plt.subplots(1,num_images,figsize=(20,10))\n",
    "\n",
    "    \n",
    "for i,ax in enumerate(axes):\n",
    "        \n",
    "    ax.imshow(imgs[i])\n",
    "    ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "#    ax.set_title(f\"label:{np.argmax(label[i])}\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af87877",
   "metadata": {},
   "source": [
    "### 3.5.2 Basic CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9760a18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#build baseline model with minimal preprocessing by applying only normalization to the images\n",
    "##input_shape=() must be in the first layer of the model, if the first layer is rescale=1./255, then add input_shape in this layer instead of conv2D\n",
    "basic_CNN_model=Sequential([\n",
    "                      Conv2D(filters=16, kernel_size=(3,3),activation='relu',padding='same',input_shape=(299,299,3)),\n",
    "                      MaxPool2D(pool_size=(2,2),strides=2),\n",
    "                      Conv2D(filters=32, kernel_size=(3,3),activation='relu'),\n",
    "                      MaxPool2D(pool_size=(2,2),strides=2),\n",
    "                      Flatten(),\n",
    "                      Dense(units=4,activation='softmax')\n",
    "                    ])\n",
    "        #rescaling layer  to normaliza the input images, use 1./255 not becasue of image dimension, but because it's related to pixel intensity range, \n",
    "        #pixel intensity is represented by 8-bit value, range from 0-255, not the height by width of the image\n",
    "        #padding is used to maintain the edge information, keep size of feature map same as input images\n",
    "        #each filter is to detect specific type of feature, each filter will produce feature map\n",
    "                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7557b936",
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_CNN_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8a492a",
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_CNN_model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d87c0844",
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_CNN_model.fit(x=train_batches,validation_data=val_batches,epochs=10,verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df0ed8da",
   "metadata": {},
   "source": [
    "### 3.5.3 Predict the Image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c75ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_batches.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a95930",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_imgs,test_labels=next(test_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938983d3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig,axes=plt.subplots(1,num_images,figsize=(20,5))\n",
    "\n",
    "    \n",
    "for i,ax in enumerate(axes):\n",
    "        \n",
    "    ax.imshow(test_imgs[i])\n",
    "    ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "    ax.set_title(f\"label:{test_labels[i]}\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13735be",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=basic_CNN_model.predict(x=test_batches,verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f3c88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.round(predictions)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ceb16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix=confusion_matrix(y_true=test_batches.classes,y_pred=np.argmax(predictions,axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90908001",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_batches.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e738cad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names=['COVID','Normal','Viral Pneumonia','Lung_Opacity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5cc170d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CM_plot(confusion_matrix, color):\n",
    "    plt.figure(figsize=(10,8))\n",
    "    sns.heatmap(confusion_matrix,annot=True,fmt='d',cmap=color,xticklabels=class_names,yticklabels=class_names)\n",
    "    plt.title('Confusion Matrix')\n",
    "   \n",
    "    #tick_marks=np.arrange(len(classes))\n",
    "    plt.xlabel=('True Label')\n",
    "    plt.ylabel=('Predicted Label')\n",
    "    plt.show()\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d76acc0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "CM_plot(confusion_matrix, \"Blues\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c503b462",
   "metadata": {},
   "source": [
    "# 3.6 CNN model with Image Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "904feab7",
   "metadata": {},
   "source": [
    "### 3.6.1 Image Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e26d86ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate batches of data which can be put in sequential model \n",
    "\n",
    "#you can add augmentation or rescaling parameters here\n",
    "#Frist, only apply augmentation to the training dataset\n",
    "\n",
    "#https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8048393/\n",
    "    \n",
    "Train_Image_generator=ImageDataGenerator(rescale=1./255,rotation_range=15,zoom_range=0.1,horizontal_flip=True, width_shift_range=0.1,brightness_range=[0.9,1.1],fill_mode='nearest')\n",
    "\n",
    "#not apply to test dataset, only rescale the validation/test dataset\n",
    "Image_generator_rescale=ImageDataGenerator(rescale=1./255)\n",
    "#creat batches of data from directory where train,val,test dataset are, target_size are set as 224 since pre-trained model VGG16 is using image with size of 224\n",
    "train_batches=Train_Image_generator.flow_from_directory(directory=base_train_dir,target_size=(299,299), classes=['COVID', 'Normal', 'Viral Pneumonia', 'Lung_Opacity'],batch_size=10)\n",
    "val_batches=Image_generator_rescale.flow_from_directory(directory=base_validation_dir,target_size=(299,299), classes=['COVID', 'Normal', 'Viral Pneumonia', 'Lung_Opacity'],batch_size=10)\n",
    "#only set shuffle to be false for test dataset since we need to use test dataset as reference for confusion matrix where\n",
    "test_batches=Image_generator_rescale.flow_from_directory(directory=base_test_dir,target_size=(299,299), classes=['COVID', 'Normal', 'Viral Pneumonia', 'Lung_Opacity'],batch_size=10,shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5769acd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Aug_CNN_model=Sequential([Conv2D(filters=16, kernel_size=(3,3),activation='relu',padding='same',input_shape=(224,224,3)),\n",
    "                      MaxPool2D(pool_size=(2,2),strides=2),\n",
    "                      Conv2D(filters=32, kernel_size=(3,3),activation='relu',padding='same'),\n",
    "                      MaxPool2D(pool_size=(2,2),strides=2),\n",
    "                      Flatten(),\n",
    "                      Dense(units=4,activation='softmax')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1aeabf89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model(model,l_r,train,val,ep,vb):\n",
    "    model.compile(optimizer=Adam(learning_rate=l_r), loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "    model.fit(x=train,validation_data=val,epochs=ep,verbose=vb)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166069fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred(model,x_test,vb):\n",
    "    predictions=model.predict(x=x_test,verbose=vb)\n",
    "    return predictions\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a515d3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CM_plot(predictions,test_batches,color):\n",
    "    confusion_matrix=confusion_matrix(y_true=test_batches.classes,y_pred=np.argmax(predictions,axis=1))\n",
    "    plt.figure(figsize=(10,8))\n",
    "    sns.heatmap(confusion_matrix,annot=True,fmt='d',cmap=color,xticklabels=class_names,yticklabels=class_names)\n",
    "    plt.title('Confusion Matrix')\n",
    "   \n",
    "    #tick_marks=np.arrange(len(classes))\n",
    "    plt.xlabel=('True Label')\n",
    "    plt.ylabel=('Predicted Label')\n",
    "    plt.show()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e262f4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "17458231",
   "metadata": {},
   "source": [
    "### 3.6.2 hyperparameter tuning for augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "390bd8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. define grid of parameters\n",
    "rotation_values=[0,5,10,20]\n",
    "zoom_values=[0,0.1,0,2]\n",
    "width_shift_values=[0,0.1]\n",
    "horizontal_flip=[True,False]\n",
    "\n",
    "augmentation_configs = []\n",
    "for width_shift in width_shift_values:\n",
    "    for rotation in rotation_values:\n",
    "        for zoom_range in zoom_values:\n",
    "            config_name = f\"ws_{width_shift}_rot_{rotation}_zoom_{zoom_range}\"\n",
    "            augmentation_configs.append({\n",
    "                'name': config_name,\n",
    "                'rotation_range': rotation,\n",
    "                'width_shift_range': width_shift,\n",
    "                'zoom_range':zoom_range,\n",
    "                'horizontal_flip':horizontal_flip\n",
    "       })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef36609f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search_augmentation(config,model,train_dir,val_dir,ep):\n",
    "    train_data_generator=ImageDataGenerator(rescale=1./255,rotation_range=config['rotation_range'],width_shift_range=config['width_shift_range'],\n",
    "                                           zoom_range=config['zoom_range'],horizontal_flip=config['horizontal_flip'],fill_mode='nearest')\n",
    "    val_data_generator=ImageDataGenerator(rescale=1./255)\n",
    "    \n",
    "    train_batches=train_data_generator.flow_from_directory(directory=train_dir,target_size=(299,299), classes=['COVID', 'Normal', 'Viral Pneumonia', 'Lung_Opacity'],batch_size=10)\n",
    "    val_batches=val_data_generator.flow_from_directory(directory=val_dir,target_size=(299,299), classes=['COVID', 'Normal', 'Viral Pneumonia', 'Lung_Opacity'],batch_size=10)\n",
    "    model=model\n",
    "    \n",
    "    history=model.fit(train_batches,epochs=ep,validation_data=val_batches,vervose=2)\n",
    "    best_val_accuracy=max(history.history['val_accuracy'])\n",
    "    return best_val_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7100590",
   "metadata": {},
   "outputs": [],
   "source": [
    "results=[]\n",
    "for config in augmentation_configs:\n",
    "    accuracy=grid_search_augmentation(config,model,train,validation)\n",
    "    results.append('configure':config['name'],'Accuracy':accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9051fe75",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(results)\n",
    "# Display the DataFrame sorted by Accuracy\n",
    "print(results_df.sort_values(by='Accuracy', ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d7adf03",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ImageML",
   "language": "python",
   "name": "imageml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
